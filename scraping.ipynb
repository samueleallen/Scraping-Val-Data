{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8tX/OwKxAFC2ZJWHn8lRu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samueleallen/Scraping-Val-Data/blob/main/scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "pkTzsvh7Kx77",
        "outputId": "6550171a-8092-431f-9c8c-3aa9e7a8f979",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2926af109324>:32: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  stats = pd.read_html(str(table))[0]\n",
            "<ipython-input-9-2926af109324>:60: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  player_stats = pd.read_html(str(table))[0]\n",
            "<ipython-input-9-2926af109324>:82: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  player_stats = pd.read_html(str(table))[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.vlr.gg/430855/jdg-esports-vs-xi-lai-gaming-champions-tour-2025-china-kickoff-lr2', 'https://www.vlr.gg/430854/nova-esports-vs-dragon-ranger-gaming-champions-tour-2025-china-kickoff-lr2', 'https://www.vlr.gg/430846/trace-esports-vs-edward-gaming-champions-tour-2025-china-kickoff-ubsf', 'https://www.vlr.gg/430518/paper-rex-vs-t1-champions-tour-2025-pacific-kickoff-ubqf', 'https://www.vlr.gg/430845/bilibili-gaming-vs-funplus-phoenix-champions-tour-2025-china-kickoff-ubsf', 'https://www.vlr.gg/430521/drx-vs-nongshim-redforce-champions-tour-2025-pacific-kickoff-ubqf', 'https://www.vlr.gg/427997/g2-esports-vs-cloud9-champions-tour-2025-americas-kickoff-ubqf', 'https://www.vlr.gg/427998/leviat-n-vs-furia-champions-tour-2025-americas-kickoff-ubqf', 'https://www.vlr.gg/430849/nova-esports-vs-wolves-esports-champions-tour-2025-china-kickoff-lr1', 'https://www.vlr.gg/430517/detonation-focusme-vs-rex-regum-qeon-champions-tour-2025-pacific-kickoff-ur1', 'https://www.vlr.gg/430850/dragon-ranger-gaming-vs-tyloo-champions-tour-2025-china-kickoff-lr1', 'https://www.vlr.gg/430516/global-esports-vs-team-secret-champions-tour-2025-pacific-kickoff-ur1', 'https://www.vlr.gg/427996/sentinels-vs-100-thieves-champions-tour-2025-americas-kickoff-ubqf', 'https://www.vlr.gg/427995/kr-esports-vs-loud-champions-tour-2025-americas-kickoff-ubqf']\n",
            "['https://www.vlr.gg/430853/xi-lai-gaming-vs-all-gamers-champions-tour-2025-china-kickoff-lr1', 'https://www.vlr.gg/430515/zeta-division-vs-nongshim-redforce-champions-tour-2025-pacific-kickoff-ur1', 'https://www.vlr.gg/430851/titan-esports-club-vs-jdg-esports-champions-tour-2025-china-kickoff-lr1', 'https://www.vlr.gg/430514/boom-esports-vs-t1-champions-tour-2025-pacific-kickoff-ur1', 'https://www.vlr.gg/427993/nrg-esports-vs-cloud9-champions-tour-2025-americas-kickoff-ur1', 'https://www.vlr.gg/427994/2game-esports-vs-furia-champions-tour-2025-americas-kickoff-ur1', 'https://www.vlr.gg/429384/team-vitality-vs-karmine-corp-champions-tour-2025-emea-kickoff-ubqf', 'https://www.vlr.gg/429385/fnatic-vs-bbl-esports-champions-tour-2025-emea-kickoff-ubqf', 'https://www.vlr.gg/430844/edward-gaming-vs-nova-esports-champions-tour-2025-china-kickoff-ubqf', 'https://www.vlr.gg/430843/trace-esports-vs-dragon-ranger-gaming-champions-tour-2025-china-kickoff-ubqf', 'https://www.vlr.gg/427992/mibr-vs-100-thieves-champions-tour-2025-americas-kickoff-ur1', 'https://www.vlr.gg/427991/evil-geniuses-vs-loud-champions-tour-2025-americas-kickoff-ur1', 'https://www.vlr.gg/429382/apeks-vs-gentle-mates-champions-tour-2025-emea-kickoff-ur1', 'https://www.vlr.gg/429379/team-liquid-vs-koi-champions-tour-2025-emea-kickoff-ur1', 'https://www.vlr.gg/430841/bilibili-gaming-vs-xi-lai-gaming-champions-tour-2025-china-kickoff-ubqf', 'https://www.vlr.gg/430842/funplus-phoenix-vs-titan-esports-club-champions-tour-2025-china-kickoff-ubqf', 'https://www.vlr.gg/429380/karmine-corp-vs-natus-vincere-champions-tour-2025-emea-kickoff-ur1', 'https://www.vlr.gg/429381/bbl-esports-vs-giantx-champions-tour-2025-emea-kickoff-ur1']\n",
            "['https://www.vlr.gg/430840/all-gamers-vs-nova-esports-champions-tour-2025-china-kickoff-ur1', 'https://www.vlr.gg/430839/jdg-esports-vs-dragon-ranger-gaming-champions-tour-2025-china-kickoff-ur1', 'https://www.vlr.gg/430837/xi-lai-gaming-vs-wolves-esports-champions-tour-2025-china-kickoff-ur1', 'https://www.vlr.gg/430838/tyloo-vs-titan-esports-club-champions-tour-2025-china-kickoff-ur1']\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2926af109324>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://www.vlr.gg/matches/results/?page={page}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/html/parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#print(\"START\", name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourcepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         tag = self.soup.handle_starttag(\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourceline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0msourcepos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourcepos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         tag = self.element_classes.get(Tag, Tag)(\n\u001b[0m\u001b[1;32m    750\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentTag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags, interesting_string_types, namespaces)\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdata_list_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m                 attrs = builder._replace_cdata_list_attribute_values(\n\u001b[0m\u001b[1;32m   1263\u001b[0m                     self.name, attrs)\n\u001b[1;32m   1264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bs4/builder/__init__.py\u001b[0m in \u001b[0;36m_replace_cdata_list_attribute_values\u001b[0;34m(self, tag_name, attrs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             tag_specific = self.cdata_list_attributes.get(\n\u001b[1;32m    313\u001b[0m                 tag_name.lower(), None)\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniversal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtag_specific\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                     \u001b[0;31m# We have a \"class\"-type attribute whose string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os # maybe not needed\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: scrape team urls from standings page\n",
        "standings_url = 'https://www.vlr.gg/vct-2024/standings'\n",
        "data = requests.get(standings_url)\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(data.text)\n",
        "\n",
        "# Locate team urls\n",
        "standings_table = soup.select('div.eg-standing-container')[0]\n",
        "links = standings_table.find_all('a')\n",
        "links = [l.get('href') for l in links]\n",
        "links = [l for l in links if '/team/' in l]\n",
        "# Format link\n",
        "team_urls = [f'https://www.vlr.gg{l}' for l in links]\n",
        "team_urls = team_urls[0]\n",
        "data = requests.get(team_urls)\n",
        "\n",
        "# Step 2: Scrape stats section data\n",
        "soup = BeautifulSoup(data.text)\n",
        "links = soup.find_all('a')\n",
        "links = [l.get(\"href\") for l in links]\n",
        "links = [l for l in links if l and 'team/stats' in l]\n",
        "# Successful, links = ['/team/stats/2359/leviat-n/']\n",
        "data = requests.get(f\"https://www.vlr.gg{links[0]}\")\n",
        "soup = BeautifulSoup(data.text)  # Create BeautifulSoup object for stats page\n",
        "table = soup.find('table', class_='wf-table mod-team-maps')\n",
        "\n",
        "# Use pandas to read the table\n",
        "stats = pd.read_html(str(table))[0]\n",
        "\n",
        "# Step 5: Filter rows that start with specific map names, kind of ruins table\n",
        "map_names = [\"Sunset\", \"Bind\", \"Haven\", \"Split\", \"Ascent\", \"Icebox\", \"Breeze\", \"Fracture\", \"Pearl\", \"Lotus\", \"Abyss\"]\n",
        "filtered_stats = stats[stats.iloc[:, 0].str.startswith(tuple(map_names), na=False)]\n",
        "\n",
        "# Display the filtered table\n",
        "# print(filtered_stats)\n",
        "\n",
        "# Individual Player Stats\n",
        "data = requests.get(team_urls)\n",
        "soup = BeautifulSoup(data.text)\n",
        "links = soup.find_all('a')\n",
        "links = [l.get(\"href\") for l in links]\n",
        "links = [l for l in links if l and 'player' in l]\n",
        "# Links provides players + staff\n",
        "player_urls = [f\"https://www.vlr.gg{l}\" for l in links]\n",
        "\n",
        "# Format player stat links to entire career\n",
        "player_stats = [f\"{l}/?timespan=all\" for l in player_urls]\n",
        "\n",
        "# Keep only players, not interested in coaches + staff\n",
        "player_stats = player_stats[:5]\n",
        "data = requests.get(player_stats[0])\n",
        "soup = BeautifulSoup(data.text)  # Create BeautifulSoup object for stats page\n",
        "table = soup.find('table', class_='wf-table')\n",
        "\n",
        "# Use pandas to read the table\n",
        "player_stats = pd.read_html(str(table))[0]\n",
        "# Table has an error in first column where it can't read agent names since they are images on website\n",
        "agent_names = []\n",
        "for img_tag in table.find_all('img'):\n",
        "    img_src = img_tag.get('src') # get image sources / agent names\n",
        "    agent_name = os.path.splitext(os.path.basename(img_src))[0]\n",
        "    agent_names.append(agent_name)\n",
        "\n",
        "player_stats['Agent'] = agent_names  # Add a new 'Agent' column\n",
        "#player_stats.head()\n",
        "# now we have a new agent column that is fully functioning! 😻\n",
        "\n",
        "# Repeat player stats scraper but for recent 90 days to understand recent performances\n",
        "player_stats = [f\"{l}/?timespan=90d\" for l in player_urls]\n",
        "\n",
        "# Keep only players, not interested in coaches + staff 🐈\n",
        "player_stats = player_stats[:5]\n",
        "data = requests.get(player_stats[0])\n",
        "soup = BeautifulSoup(data.text)  # Create BeautifulSoup object for stats page\n",
        "table = soup.find('table', class_='wf-table')\n",
        "\n",
        "# Use pandas to read the table\n",
        "player_stats = pd.read_html(str(table))[0]\n",
        "# Table has an error in first column where it can't read agent names since they are images on website 😿\n",
        "agent_names = []\n",
        "for img_tag in table.find_all('img'):\n",
        "    img_src = img_tag.get('src') # get image sources / agent names\n",
        "    agent_name = os.path.splitext(os.path.basename(img_src))[0]\n",
        "    agent_names.append(agent_name)\n",
        "\n",
        "player_stats['Agent'] = agent_names  # Add a new 'Agent' column\n",
        "\n",
        "# I have all-time player stats, past 90 days player stats, team map stats, now we need match up stats for teams 😸\n",
        "# Ex: fnatic vs sentinels, sentinels has won x out of y matchups\n",
        "matches_url = 'https://www.vlr.gg/matches'\n",
        "data = requests.get(matches_url)\n",
        "soup = BeautifulSoup(data.text)\n",
        "links = soup.find_all('a')\n",
        "links = [l.get(\"href\") for l in links]\n",
        "links = [l for l in links if l and 'page' in l]\n",
        "url = \"https://www.vlr.gg/matches/results\"  # Replace with the actual URL\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all page number links\n",
        "page_links = soup.find_all(\"a\", class_=\"btn mod-page\")\n",
        "# Page_links holds a list of HTML <a> elements beautiful soup found\n",
        "# Now extract the page numbers\n",
        "page_numbers = [int(link.text) for link in page_links if link.text.isdigit()]\n",
        "\n",
        "# Get the max page number\n",
        "max_page = max(page_numbers)\n",
        "from itertools import chain\n",
        "for page in range(1, max_page+1): # For loop starts from page 1 ends at max page\n",
        "    url = f\"https://www.vlr.gg/matches/results/?page={page}\"\n",
        "    data = requests.get(url)\n",
        "    soup = BeautifulSoup(data.text, \"html.parser\")\n",
        "    links = soup.find_all('a')\n",
        "    links = [l.get(\"href\") for l in links]\n",
        "    # Filter links to only include recent years, champions tour matches, and not acension champions tour matches\n",
        "    links = [l for l in links if l and 'champions-tour' in l and ('2023' in l or '2024' in l or '2025' in l) and 'ascension' not in l and 'challengers' not in l]\n",
        "    matches = [f\"https://www.vlr.gg{l}\" for l in links]\n",
        "    # matches is a list of lists? Erm... what the sigma? 😾\n",
        "\n"
      ]
    }
  ]
}